"""
Chancify AI - Backend API
FastAPI application for college admissions probability calculations
"""

import os
import logging
import time
import numpy as np
import pandas as pd
from typing import Dict, Any
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from config import settings
from database import create_tables
from data.real_ipeds_major_mapping import get_colleges_for_major, get_major_strength_score, get_major_relevance_info
from data.real_college_suggestions import real_college_suggestions
from data.college_names_mapping import college_names_mapping
from data.college_nickname_mapper import nickname_mapper
from data.college_subject_emphasis import college_subject_emphasis
from data.tuition_state_service import tuition_state_service
from data.improvement_analysis_service import improvement_analysis_service

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Simple in-memory cache for college suggestions
suggestion_cache = {}
CACHE_DURATION = 300  # 5 minutes

# Helper functions for JSON-compliant values
def safe_float(value, default=0.0):
    """Convert value to float, handling NaN, None, and infinity"""
    if value is None:
        return default
    
    # Handle string inputs
    if isinstance(value, str):
        if not value.strip():
            return default
        try:
            float_val = float(value)
        except (ValueError, TypeError):
            return default
    else:
        try:
            float_val = float(value)
        except (ValueError, TypeError):
            return default
    
    # Check for NaN and infinity - only after conversion to float
    try:
        if pd.isna(float_val) or np.isinf(float_val):
            return default
    except (TypeError, ValueError):
        return default
    
    return float_val

def safe_int(value, default=0):
    """Convert value to int, handling NaN, None, and invalid values"""
    if value is None:
        return default
    
    # Handle string inputs
    if isinstance(value, str):
        if not value.strip():
            return default
        try:
            int_val = int(float(value))  # Convert via float first to handle "3.0" strings
        except (ValueError, TypeError):
            return default
    else:
        try:
            int_val = int(value)
        except (ValueError, TypeError):
            return default
    
    return int_val

def safe_round(value, decimals=4, default=0.0):
    """Round value to specified decimals, handling NaN, None, and infinity"""
    safe_val = safe_float(value, default)
    return round(safe_val, decimals)

# Get environment
ENV = os.getenv("ENVIRONMENT", "development")

# Initialize FastAPI app
app = FastAPI(
    title="Chancify AI API",
    description="College admissions probability calculator with personalized game plans",
    version="0.1.0",
    docs_url="/api/docs",
    redoc_url="/api/redoc"
)

# CORS middleware configuration
# Allow all origins in production (Railway deployment)
allowed_origins = [
    "http://localhost:3000",  # Local development
    "http://localhost:3001",  # Local development (alt port)
    "https://chancifyai.up.railway.app",  # Railway frontend
    settings.frontend_url
]

# In production, allow Railway domains
if ENV == "production":
    allowed_origins.append("*")  # Allow all origins for Railway

app.add_middleware(
    CORSMiddleware,
    allow_origins=allowed_origins if ENV == "development" else ["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Create database tables on startup
@app.on_event("startup")
async def startup_event():
    """Initialize database tables."""
    logger.info(f"Starting Chancify AI API in {ENV} mode")
    logger.info(f"Python path: {os.environ.get('PYTHONPATH', 'not set')}")
    logger.info(f"Working directory: {os.getcwd()}")
    
    try:
        create_tables()
        logger.info("✓ Database tables created/verified successfully")
    except Exception as e:
        logger.warning(f"⚠ Database initialization failed: {e}")
        logger.warning("  API will continue without database features")
    
    logger.info("✓ Chancify AI API started successfully")

@app.get("/")
async def root():
    """Root health check endpoint"""
    return {
        "status": "healthy",
        "message": "Chancify AI API is running",
        "version": "0.1.0",
        "environment": ENV
    }

@app.get("/api/health")
async def health_check():
    """Detailed health check for Railway"""
    # Test database connection
    db_status = "unknown"
    try:
        from database.connection import engine
        from sqlalchemy import text
        if engine is not None:
            # Try a simple query to verify connection
            with engine.connect() as conn:
                conn.execute(text("SELECT 1"))
            db_status = "connected"
        else:
            db_status = "not_initialized"
    except Exception as e:
        logger.warning(f"Database health check failed: {e}")
        db_status = "error"
    
    return {
        "status": "healthy",
        "database": db_status,
        "scoring_system": "loaded",
        "environment": ENV,
        "port": os.environ.get("PORT", "8000")
    }

@app.get("/api/search/colleges")
async def search_colleges(q: str = "", limit: int = 20):
    """
    Search colleges by name, nickname, or abbreviation.
    
    This endpoint searches through official names, common names, and abbreviations
    to find colleges matching the query.
    
    Args:
        q: Search query (college name, nickname, or abbreviation)
        limit: Maximum number of results to return (default: 20, max: 100)
        
    Returns:
        JSON response with matching colleges and their data
    """
    try:
        # Validate limit
        limit = min(max(1, limit), 100)
        
        if not q or len(q.strip()) < 2:
            return {
                "success": True,
                "colleges": [],
                "total": 0,
                "message": "Please provide a search query with at least 2 characters"
            }
        
        # Search for colleges directly in the CSV data (bypass names mapping)
        try:
            college_df = pd.read_csv('data/raw/real_colleges_integrated.csv')
        except Exception as e:
            logger.error(f"Error loading college data: {e}")
            return {
                "success": False,
                "colleges": [],
                "total": 0,
                "error": "Unable to load college data"
            }
        
        # Search for colleges directly in the CSV data
        query = q.strip().lower()
        matching_colleges = []
        
        # First, try to find college by nickname/abbreviation
        official_name = nickname_mapper.find_college_by_nickname(q)
        logger.info(f"Nickname search for '{q}': {official_name}")
        
        # If we found an official name from nickname mapping, search for that
        if official_name:
            logger.info(f"Searching for official name: {official_name}")
            for _, row in college_df.iterrows():
                college_name = str(row.get('name', '')).lower()
                if official_name.lower() in college_name or college_name in official_name.lower():
                    matching_colleges.append(row)
                    logger.info(f"Found match: {row.get('name', '')}")
        
        # If no matches from nickname mapping, do regular search
        if not matching_colleges:
            logger.info(f"No nickname matches, doing regular search for: {query}")
            
            # Search through college names
            for _, row in college_df.iterrows():
                college_name = str(row.get('name', '')).lower()
                if query in college_name:
                    matching_colleges.append(row)
            
            # If still no matches, try broader search
            if not matching_colleges:
                logger.info("No direct matches, trying broader search")
                for _, row in college_df.iterrows():
                    college_name = str(row.get('name', '')).lower()
                    city = str(row.get('city', '')).lower()
                    state = str(row.get('state', '')).lower()
                    
                    if (query in city or query in state or 
                        any(word.startswith(query) for word in college_name.split())):
                        matching_colleges.append(row)
        
        # Limit results
        matching_colleges = matching_colleges[:limit]
        
        if not matching_colleges:
            return {
                "success": True,
                "colleges": [],
                "total": 0,
                "message": f"No colleges found matching '{q}'"
            }
        
        # Format results
        results = []
        for row in matching_colleges:
            college_data = {
                "college_id": f"college_{row.get('unitid', 'unknown')}",
                "name": row.get('name', ''),
                "acceptance_rate": safe_float(row.get('acceptance_rate', 0.5), 0.5),
                "selectivity_tier": row.get('selectivity_tier', 'Moderately Selective'),
                "city": row.get('city', ''),
                "state": row.get('state', ''),
                "tuition_in_state": safe_float(row.get('tuition_in_state_usd', 0), 0),
                "tuition_out_of_state": safe_float(row.get('tuition_out_of_state_usd', 0), 0),
                "student_body_size": safe_float(row.get('student_body_size', 0), 0),
                "name_variations": {
                    "official": row.get('name', '').lower(),
                    "common": row.get('name', '').lower()  # Use same as official for now
                }
            }
            results.append(college_data)
        
        return {
            "success": True,
            "colleges": results,
            "total": len(results),
            "query": q,
            "nickname_matched": official_name is not None,
            "message": f"Found {len(results)} colleges matching '{q}'"
        }
        
    except Exception as e:
        logger.error(f"Error in search_colleges: {e}")
        return {
            "success": False,
            "colleges": [],
            "total": 0,
            "error": str(e)
        }

@app.get("/api/college-subject-emphasis/{college_name}",
         summary="Get college subject emphasis",
         description="Get real-time subject emphasis percentages for a college using OpenAI API",
         tags=["College Subject Emphasis"])
async def get_college_subject_emphasis(college_name: str):
    """
    Get subject emphasis percentages for a specific college.
    
    This endpoint uses OpenAI API to analyze the college's academic focus
    and return percentage emphasis for different subject areas.
    
    Args:
        college_name: Name of the college
        
    Returns:
        JSON response with subject emphasis percentages
    """
    try:
        logger.info(f"Getting subject emphasis for: {college_name}")
        
        # Get subject emphasis data
        subject_data = college_subject_emphasis.get_subject_emphasis_with_cache(college_name, suggestion_cache)
        
        # Format for frontend
        subjects = []
        for subject, percentage in subject_data.items():
            subjects.append({
                "label": subject,
                "value": percentage
            })
        
        logger.info(f"Subject emphasis retrieved for {college_name}: {len(subjects)} subjects")
        
        return {
            "success": True,
            "college_name": college_name,
            "subjects": subjects,
            "total_subjects": len(subjects)
        }
        
    except Exception as e:
        logger.error(f"Error getting subject emphasis for {college_name}: {e}")
        return {
            "success": False,
            "college_name": college_name,
            "subjects": [],
            "error": str(e)
        }

@app.get("/api/college-tuition/{college_name}",
         summary="Get college tuition data",
         description="Get real tuition and cost data for a college",
         tags=["College Tuition"])
async def get_college_tuition(college_name: str):
    """
    Get tuition and cost data for a specific college.
    
    This endpoint returns real tuition, fees, room & board, and other costs
    for the specified college.
    
    Args:
        college_name: Name of the college
        
    Returns:
        JSON response with tuition and cost information
    """
    try:
        logger.info(f"Getting tuition data for: {college_name}")
        
        # Get tuition data
        tuition_data = college_tuition_service.get_tuition_data_with_cache(college_name, suggestion_cache)
        
        logger.info(f"Tuition data retrieved for {college_name}: ${tuition_data['total_in_state']:,} total")
        
        return {
            "success": True,
            "college_name": college_name,
            "tuition_data": tuition_data
        }
        
    except Exception as e:
        logger.error(f"Error getting tuition data for {college_name}: {e}")
        return {
            "success": False,
            "college_name": college_name,
            "tuition_data": None,
            "error": str(e)
        }

@app.get("/api/tuition-by-zipcode/{college_name}/{zipcode}",
         summary="Get tuition based on zipcode",
         description="Get in-state or out-of-state tuition for a college based on zipcode",
         tags=["Tuition State"])
async def get_tuition_by_zipcode(college_name: str, zipcode: str):
    """
    Get tuition information for a college based on zipcode.
    
    This endpoint determines if the zipcode qualifies for in-state tuition
    and returns the appropriate tuition amount.
    
    Args:
        college_name: Name of the college
        zipcode: User's zipcode
        
    Returns:
        JSON response with tuition information and state determination
    """
    try:
        logger.info(f"Getting tuition for {college_name} with zipcode {zipcode}")
        
        # Get tuition data based on zipcode
        result = tuition_state_service.get_tuition_for_college_and_zipcode(college_name, zipcode)
        
        if result['success']:
            logger.info(f"Tuition determined for {college_name}: ${result['tuition']:,} ({'in-state' if result['is_in_state'] else 'out-of-state'})")
        
        return result
        
    except Exception as e:
        logger.error(f"Error getting tuition for {college_name} with zipcode {zipcode}: {e}")
        return {
            "success": False,
            "error": str(e),
            "college_name": college_name,
            "zipcode": zipcode,
            "is_in_state": None,
            "tuition": None
        }

@app.post("/api/improvement-analysis/{college_name}",
         summary="Get personalized improvement recommendations",
         description="Analyze user profile against college requirements and provide improvement areas",
         tags=["Improvement Analysis"])
async def get_improvement_analysis(college_name: str, user_profile: Dict[str, Any]):
    """
    Get personalized improvement recommendations for a specific college.
    
    This endpoint analyzes the user's profile against the college's requirements
    and provides specific, actionable improvement areas.
    
    Args:
        college_name: Name of the college
        user_profile: User's academic and extracurricular profile
        
    Returns:
        JSON response with improvement areas and recommendations
    """
    try:
        logger.info(f"Getting improvement analysis for {college_name}")
        
        # Get improvement recommendations
        improvements = improvement_analysis_service.analyze_user_profile(user_profile, college_name)
        
        # Calculate combined impact
        combined_impact = improvement_analysis_service.calculate_combined_impact(improvements)
        
        # Convert to JSON-serializable format
        improvements_data = []
        for imp in improvements:
            improvements_data.append({
                "area": imp.area,
                "current": imp.current,
                "target": imp.target,
                "impact": imp.impact,
                "priority": imp.priority,
                "description": imp.description,
                "actionable_steps": imp.actionable_steps
            })
        
        result = {
            "success": True,
            "college_name": college_name,
            "improvements": improvements_data,
            "combined_impact": combined_impact,
            "total_improvements": len(improvements)
        }
        
        logger.info(f"Generated {len(improvements)} improvement recommendations for {college_name}")
        return result
        
    except Exception as e:
        logger.error(f"Error getting improvement analysis for {college_name}: {e}")
        return {
            "success": False,
            "error": str(e),
            "college_name": college_name,
            "improvements": [],
            "combined_impact": 0
        }

# Include API routes
from api.routes import calculations, ml_calculations, openai_routes, auth
from services.openai_service import college_info_service
from ml.models.predictor import get_predictor
from ml.preprocessing.feature_extractor import StudentFeatures, CollegeFeatures
from pydantic import BaseModel
import pandas as pd

app.include_router(auth.router, prefix="/api/auth", tags=["Authentication"])
app.include_router(calculations.router, prefix="/api/calculations", tags=["Probability Calculations"])
app.include_router(ml_calculations.router, prefix="/api/calculations", tags=["ML Predictions"])
app.include_router(openai_routes.router, prefix="/api/openai", tags=["OpenAI College Info"])

# College data mapping based on training data
def get_college_data(college_name: str) -> Dict[str, Any]:
    """Get college data based on college name from integrated data."""
    
    logger.info(f"Getting college data for: {college_name}")
    
    # Load the integrated college data
    try:
        df = pd.read_csv('data/raw/real_colleges_integrated.csv')
        logger.info(f"Loaded college data: {df.shape}")
        
        # Check if the input is a college ID (format: college_XXXXXX)
        college_row = None
        if college_name.startswith('college_'):
            college_id = college_name.replace('college_', '')
            logger.info(f"Looking for college ID: {college_id}")
            
            # Try to find by unitid (MOST COMMON CASE)
            college_row = df[df['unitid'] == int(college_id)]
            logger.info(f"Found by unitid: {len(college_row)} rows")
            
            if not college_row.empty:
                logger.info(f"✅ SUCCESS: Found college by ID")
            else:
                logger.warning(f"❌ FAILED: No college found with unitid={college_id}")
        else:
            # Find the college by name (case-insensitive, with exact matching first)
            college_name_lower = college_name.lower()
            college_row = df[df['name'].str.lower() == college_name_lower]
            logger.info(f"Exact match found: {len(college_row)} rows")
            
            # If exact match not found, try partial matching but prefer shorter matches
            if college_row.empty:
                college_row = df[df['name'].str.lower().str.contains(college_name_lower, na=False)]
                logger.info(f"Partial match found: {len(college_row)} rows")
                # If multiple matches, prefer the one with the shortest name (most specific)
                if not college_row.empty and len(college_row) > 1:
                    college_row = college_row.loc[college_row['name'].str.len().idxmin():college_row['name'].str.len().idxmin()]
        
        if college_row is not None and not college_row.empty:
            row = college_row.iloc[0]
            logger.info(f"Found college: {row['name']}")
            # Debug: Print all column names and the name value
            logger.info(f"CSV columns: {list(row.index)}")
            logger.info(f"Row name value: {row.get('name', 'MISSING_NAME_COLUMN')}")
            logger.info(f"Row name type: {type(row.get('name'))}")
            logger.info(f"Row name is NaN: {pd.isna(row.get('name'))}")
            
            # Try to get name from different possible column names
            college_actual_name = None
            if pd.notna(row.get('name')):
                college_actual_name = str(row['name'])
            elif pd.notna(row.get('Name')):
                college_actual_name = str(row['Name'])
            elif pd.notna(row.get('institution_name')):
                college_actual_name = str(row['institution_name'])
            else:
                college_actual_name = college_name  # Fallback to original input
            
            result = {
                'name': college_actual_name,
                'acceptance_rate': float(row.get('acceptance_rate', 0.5)) if pd.notna(row.get('acceptance_rate')) else (float(row.get('acceptance_rate_percent', 50)) / 100 if pd.notna(row.get('acceptance_rate_percent')) else 0.5),
                'sat_25th': 1200,  # Default values since SAT/ACT data not available
                'sat_75th': 1500,
                'act_25th': 25,
                'act_75th': 35,
                'test_policy': str(row.get('test_policy', 'Required')),
                'financial_aid_policy': str(row.get('financial_aid_policy', 'Need-blind')),
                'selectivity_tier': str(row.get('selectivity_tier', 'Moderately Selective')),
                'gpa_average': float(row.get('gpa_average', 3.7)) if pd.notna(row.get('gpa_average')) else 3.7,
                'city': str(row.get('city', 'Unknown')) if pd.notna(row.get('city')) else "Unknown",
                'state': str(row.get('state', 'Unknown')) if pd.notna(row.get('state')) else "Unknown",
                'tuition_in_state': int(row.get('tuition_in_state_usd', 20000)) if pd.notna(row.get('tuition_in_state_usd')) else 20000,
                'tuition_out_of_state': int(row.get('tuition_out_of_state_usd', 40000)) if pd.notna(row.get('tuition_out_of_state_usd')) else 40000,
                'student_body_size': int(row.get('student_body_size', 5000)) if pd.notna(row.get('student_body_size')) else 5000,
                'is_public': str(row.get('control', 'Private')).lower() == 'public' if pd.notna(row.get('control')) else False
            }
            logger.info(f"Returning college data: {result}")
            return result
        else:
            logger.warning(f"No college found for: {college_name}")
    except Exception as e:
        logger.warning(f"Could not load college data: {e}")
    
    # Default fallback data
    logger.info(f"Returning fallback data for: {college_name}")
    return {
        'name': college_name,
        'acceptance_rate': 0.1,
        'sat_25th': 1200,
        'sat_75th': 1500,
        'act_25th': 25,
        'act_75th': 35,
        'test_policy': 'Required',
        'financial_aid_policy': 'Need-blind',
        'selectivity_tier': 'Elite',
        'gpa_average': 3.7,
        'city': "Unknown",
        'state': "Unknown",
        'tuition_in_state': 20000,
        'tuition_out_of_state': 40000,
        'student_body_size': 5000
    }

# Frontend profile request model (matches frontend format)
class FrontendProfileRequest(BaseModel):
    # Academic data
    gpa_unweighted: str = "3.5"
    gpa_weighted: str = "3.8"
    sat: str = "1200"
    act: str = "25"
    
    # Course rigor and class info
    rigor: str = "5"
    ap_count: str = "0"
    honors_count: str = "0"
    class_rank_percentile: str = "50"
    class_size: str = "300"
    
    # Factor scores (1-10 scale from frontend dropdowns)
    extracurricular_depth: str = "5"
    leadership_positions: str = "5"
    awards_publications: str = "5"
    passion_projects: str = "5"
    business_ventures: str = "5"
    volunteer_work: str = "5"
    research_experience: str = "5"
    portfolio_audition: str = "5"
    essay_quality: str = "5"
    recommendations: str = "5"
    interview: str = "5"
    demonstrated_interest: str = "5"
    legacy_status: str = "5"
    hs_reputation: str = "5"
    
    # Additional ML model fields (derived from dropdowns)
    geographic_diversity: str = "5"
    plan_timing: str = "5"
    geography_residency: str = "5"
    firstgen_diversity: str = "5"
    ability_to_pay: str = "5"
    policy_knob: str = "5"
    conduct_record: str = "9"
    
    # Major and college
    major: str = "Computer Science"
    college: str = "Stanford University"

# Legacy prediction request model (for backward compatibility)
class PredictionRequest(BaseModel):
    # Academic data
    gpa_unweighted: float
    gpa_weighted: float
    sat: int
    act: int
    rigor: int
    
    # Unique factors
    extracurricular_depth: int
    leadership_positions: int
    awards_publications: int
    passion_projects: int
    business_ventures: int
    volunteer_work: int
    research_experience: int
    portfolio_audition: int
    essay_quality: int
    recommendations: int
    interview: int
    demonstrated_interest: int
    legacy_status: int
    geographic_diversity: int
    firstgen_diversity: int
    major: str
    hs_reputation: int
    
    # College selection
    college: str

@app.post("/api/predict/frontend")
async def predict_admission_frontend(request: FrontendProfileRequest):
    """Predict admission probability using hybrid ML+Formula system for frontend"""
    try:
        # Get predictor
        predictor = get_predictor()
        
        # Convert frontend string values to appropriate types
        def safe_int(value: str) -> int:
            try:
                return int(value) if value and value.strip() else 0
            except (ValueError, TypeError):
                return 0
        
        # Calculate derived factor scores from real data
        gpa_unweighted = safe_float(request.gpa_unweighted)
        gpa_weighted = safe_float(request.gpa_weighted)
        sat_score = safe_int(request.sat)
        act_score = safe_int(request.act)
        
        # Calculate grades score from GPA (0-10 scale)
        def calculate_grades_score(gpa_unweighted, gpa_weighted):
            if gpa_unweighted > 0:
                # Convert 4.0 scale to 10.0 scale
                return min(10.0, (gpa_unweighted / 4.0) * 10.0)
            elif gpa_weighted > 0:
                # Convert 5.0 scale to 10.0 scale
                return min(10.0, (gpa_weighted / 5.0) * 10.0)
            return 5.0  # Default neutral
        
        # Calculate testing score from SAT/ACT (0-10 scale)
        def calculate_testing_score(sat, act):
            if sat > 0:
                # FIXED: More realistic SAT scoring - 1200=5.0, 1600=10.0
                return min(10.0, max(0.0, ((sat - 1200) / 400) * 5.0 + 5.0))
            elif act > 0:
                # FIXED: More realistic ACT scoring - 20=5.0, 36=10.0
                return min(10.0, max(0.0, ((act - 20) / 16) * 5.0 + 5.0))
            return 5.0  # Default neutral
        
        # Calculate major fit score based on major relevance
        def calculate_major_fit_score(major, college_name):
            # This would ideally use a major-college relevance database
            # For now, use a simple heuristic based on major popularity
            popular_majors = ['Computer Science', 'Business', 'Engineering', 'Biology', 'Psychology']
            if major in popular_majors:
                return 7.0  # Good fit for popular majors
            return 6.0  # Neutral fit
        
        # Create student features from frontend data
        student = StudentFeatures(
            # Academic metrics
            gpa_unweighted=gpa_unweighted,
            gpa_weighted=gpa_weighted,
            sat_total=sat_score,
            act_composite=act_score,
            
            # Course rigor and class info
            ap_count=int(safe_float(request.extracurricular_depth) * 2),  # Estimate based on extracurricular depth
            honors_count=int(safe_float(request.extracurricular_depth) * 1.5),  # Estimate based on extracurricular depth
            class_rank_percentile=safe_float(request.hs_reputation) * 10,  # Estimate based on HS reputation
            class_size=500,  # Default class size
            
            # Extracurricular counts and commitment
            ec_count=min(10, max(1, safe_int(request.extracurricular_depth) // 2)),  # Derive from extracurricular depth
            leadership_positions_count=safe_int(request.leadership_positions),
            years_commitment=min(6, max(1, safe_int(request.extracurricular_depth) // 2)),  # Derive from extracurricular depth
            hours_per_week=min(20.0, max(2.0, safe_float(request.extracurricular_depth) * 1.5)),  # Derive from extracurricular depth
            awards_count=safe_int(request.awards_publications),
            national_awards=min(5, max(0, safe_int(request.awards_publications) // 2)),  # Derive from awards/publications
            
            # Demographics and diversity
            first_generation=safe_float(request.firstgen_diversity) > 7.0,  # Derive from firstgen_diversity
            underrepresented_minority=safe_float(request.firstgen_diversity) > 6.0,  # Derive from firstgen_diversity
            geographic_diversity=safe_float(request.geographic_diversity),
            legacy_status=bool(safe_int(request.legacy_status)),
            recruited_athlete=safe_float(request.volunteer_work) > 7.0,  # Derive from volunteer_work
            
            # Factor scores (calculated from real data, not defaults)
            factor_scores={
                'grades': calculate_grades_score(gpa_unweighted, gpa_weighted),
                'rigor': safe_float(request.extracurricular_depth),  # Use extracurricular depth as rigor proxy
                'testing': calculate_testing_score(sat_score, act_score),
                'essay': safe_float(request.essay_quality),
                'ecs_leadership': safe_float(request.extracurricular_depth),
                'recommendations': safe_float(request.recommendations),
                'plan_timing': safe_float(request.plan_timing),
                'athletic_recruit': safe_float(request.volunteer_work),  # Use volunteer_work as proxy
                'major_fit': calculate_major_fit_score(request.major, "Unknown"),  # No specific college for suggestions
                'geography_residency': safe_float(request.geography_residency),
                'firstgen_diversity': safe_float(request.firstgen_diversity),
                'ability_to_pay': safe_float(request.ability_to_pay),
                'awards_publications': safe_float(request.awards_publications),
                'portfolio_audition': safe_float(request.portfolio_audition),
                'policy_knob': safe_float(request.policy_knob),
                'demonstrated_interest': safe_float(request.demonstrated_interest),
                'legacy': safe_float(request.legacy_status),
                'interview': safe_float(request.interview),
                'conduct_record': safe_float(request.conduct_record),
                'hs_reputation': safe_float(request.hs_reputation)
            }
        )
        
        # Get college data with real acceptance rate from OpenAI
        college_data = get_college_data(request.college)
        logger.info(f"College data retrieved: {college_data}")
        logger.info(f"College name: {college_data.get('name', 'MISSING')}")
        logger.info(f"College city: {college_data.get('city', 'MISSING')}")
        logger.info(f"College state: {college_data.get('state', 'MISSING')}")
        
        # Get real acceptance rate and subject emphasis from OpenAI API
        try:
            college_info = await college_info_service.get_college_info(college_data['name'])
            real_acceptance_rate = college_info['academics']['acceptance_rate']
            print(f"Using real acceptance rate for {college_data['name']}: {real_acceptance_rate:.1%}")
            
            # Get subject emphasis data
            subject_data = await college_info_service.get_college_subject_emphasis(college_data['name'])
            subject_emphasis = subject_data['subject_emphasis']
            print(f"Using real subject emphasis for {college_data['name']}: {len(subject_emphasis)} subjects")
        except Exception as e:
            print(f"Failed to get OpenAI data for {college_data['name']}: {e}")
            real_acceptance_rate = college_data['acceptance_rate']  # Fallback to database value
            subject_emphasis = [
                {"label": "Computer Science", "value": 28},
                {"label": "Engineering", "value": 24},
                {"label": "Business", "value": 16},
                {"label": "Biological Sciences", "value": 14},
                {"label": "Mathematics & Stats", "value": 11},
                {"label": "Social Sciences", "value": 9},
                {"label": "Arts & Humanities", "value": 7},
                {"label": "Education", "value": 5}
            ]
        
        college = CollegeFeatures(
            name=college_data['name'],
            acceptance_rate=real_acceptance_rate,  # Use real acceptance rate from OpenAI
            sat_25th=college_data['sat_25th'],
            sat_75th=college_data['sat_75th'],
            act_25th=college_data['act_25th'],
            act_75th=college_data['act_75th'],
            test_policy=college_data['test_policy'],
            financial_aid_policy=college_data['financial_aid_policy'],
            selectivity_tier=college_data['selectivity_tier'],
            gpa_average=college_data['gpa_average']
        )
        
        # Make hybrid prediction
        result = predictor.predict(student, college, model_name='ensemble', use_formula=True)
        
        # Determine category based on final probability
        # Use same thresholds as suggestions endpoint: Safety: 75%+, Target: 25-75%, Reach: 10-25%
        prob = result.probability
        if prob >= 0.75:
            category = "safety"
        elif prob >= 0.25:
            category = "target"
        elif prob >= 0.10:
            category = "reach"
        else:
            category = "reach"  # Default to reach for very low probabilities
        
        return {
            "success": True,
            "college_id": request.college,
            "college_name": college_data['name'],
            "probability": round(result.probability, 4),
            "confidence_interval": {
                "lower": round(result.confidence_interval[0], 4),
                "upper": round(result.confidence_interval[1], 4)
            },
            "ml_probability": round(result.ml_probability, 4),
            "formula_probability": round(result.formula_probability, 4),
            "ml_confidence": round(result.ml_confidence, 4),
            "blend_weights": result.blend_weights,
            "model_used": result.model_used,
            "prediction_method": "hybrid_ml_formula",
            "explanation": result.explanation,
            "category": category,
            "acceptance_rate": real_acceptance_rate,  # Use real acceptance rate from OpenAI
            "selectivity_tier": college_data['selectivity_tier'],
            # Return full college data for frontend
            "college_data": {
                "name": college_data['name'],
                "city": college_data['city'],
                "state": college_data['state'],
                "is_public": college_data.get('is_public', False),
                "tuition_in_state": college_data['tuition_in_state'],
                "tuition_out_of_state": college_data['tuition_out_of_state'],
                "student_body_size": college_data['student_body_size'],
                "test_policy": college_data['test_policy'],
                "financial_aid_policy": college_data['financial_aid_policy'],
                "gpa_average": college_data['gpa_average']
            },
            # Return subject emphasis data from OpenAI
            "subject_emphasis": subject_emphasis
        }
        
    except Exception as e:
        logger.error(f"Frontend prediction error: {e}")
        return {
            "success": False,
            "error": str(e),
            "message": "Prediction failed. Please try again."
        }

# College suggestions request model (simplified)
# This model receives user profile data from the frontend and generates
# AI-powered college suggestions based on academic strength and preferences
# Updated with elite universities integration - 19 elite universities now included
class CollegeSuggestionsRequest(BaseModel):
    # Essential academic data - core metrics for college admissions
    gpa_unweighted: str = "3.5"      # Unweighted GPA (0.0-4.0 scale)
    gpa_weighted: str = "3.8"        # Weighted GPA (0.0-5.0+ scale)
    sat: str = "1200"                 # SAT total score (400-1600)
    act: str = "25"                   # ACT composite score (1-36)
    major: str = "Computer Science"   # Intended major of study
    
    # Factor scores (1-10 scale from frontend dropdowns)
    # These represent the user's strength in various admission factors
    extracurricular_depth: str = "5"      # Depth and commitment to activities
    leadership_positions: str = "5"       # Leadership roles and responsibilities
    awards_publications: str = "5"        # Awards, honors, and publications
    passion_projects: str = "5"           # Personal projects and initiatives
    business_ventures: str = "5"          # Entrepreneurial activities
    volunteer_work: str = "5"             # Community service and volunteering
    research_experience: str = "5"        # Academic research involvement
    portfolio_audition: str = "5"         # Creative portfolio or audition quality
    essay_quality: str = "5"              # Personal statement and essay quality
    recommendations: str = "5"            # Letter of recommendation strength
    interview: str = "5"                  # Interview performance
    demonstrated_interest: str = "5"      # Show of interest in specific colleges
    legacy_status: str = "5"              # Legacy status (family alumni)
    hs_reputation: str = "5"              # High school reputation and rigor
    
    # Additional ML model fields (derived from dropdowns)
    # These provide additional context for the ML model
    geographic_diversity: str = "5"       # Geographic diversity factor
    plan_timing: str = "5"                # Application timing (early/regular)
    geography_residency: str = "5"        # In-state vs out-of-state status
    firstgen_diversity: str = "5"         # First-generation college student status
    ability_to_pay: str = "5"             # Financial need and ability to pay
    policy_knob: str = "5"                # Policy-related factors
    conduct_record: str = "9"             # Disciplinary record status

@app.post("/api/suggest/colleges")
async def suggest_colleges(request: CollegeSuggestionsRequest):
    """
    Get AI-suggested colleges based on user profile using real IPEDS data.
    
    This endpoint:
    1. Processes user profile data from frontend
    2. Calculates academic strength score
    3. Uses real IPEDS data to find colleges strong in the user's major
    4. Categorizes colleges into Safety/Target/Reach based on realistic probability ranges
    5. Returns balanced suggestions (3 safety, 3 target, 3 reach) with accurate major relevance
    
    Args:
        request: CollegeSuggestionsRequest containing user profile data
        
    Returns:
        JSON response with 9 balanced college suggestions and metadata
    """
    try:
        # Create cache key from request data
        cache_key = f"{request.gpa_unweighted}_{request.gpa_weighted}_{request.sat}_{request.act}_{request.major}_{request.extracurricular_depth}"
        
        # Check cache first
        current_time = time.time()
        if cache_key in suggestion_cache:
            cached_data, cache_time = suggestion_cache[cache_key]
            if current_time - cache_time < CACHE_DURATION:
                logger.info(f"Returning cached suggestions for key: {cache_key[:20]}...")
                return cached_data
        
        logger.info(f"Processing new suggestions for key: {cache_key[:20]}...")
        
        # Convert frontend string values to appropriate types
        def safe_int(value: str) -> int:
            try:
                return int(value) if value and value.strip() else 0
            except (ValueError, TypeError):
                return 0
        
        # Calculate academic strength
        gpa_unweighted = safe_float(request.gpa_unweighted)
        gpa_weighted = safe_float(request.gpa_weighted)
        sat_score = safe_int(request.sat)
        act_score = safe_int(request.act)
        
        # Calculate academic strength (0-10 scale)
        gpa_score = min(10.0, (gpa_unweighted / 4.0) * 10.0) if gpa_unweighted > 0 else 5.0
        sat_score_scaled = min(10.0, max(0.0, ((sat_score - 1200) / 400) * 5.0 + 5.0)) if sat_score > 0 else 5.0
        act_score_scaled = min(10.0, max(0.0, ((act_score - 20) / 16) * 5.0 + 5.0)) if act_score > 0 else 5.0
        
        # Use the higher of SAT or ACT
        test_score = max(sat_score_scaled, act_score_scaled)
        
        # Calculate academic strength (0-10 scale)
        academic_strength = (gpa_score + test_score) / 2.0
        
        # Calculate extracurricular strength
        ec_strength = (
            safe_float(request.extracurricular_depth) +
            safe_float(request.leadership_positions) +
            safe_float(request.awards_publications) +
            safe_float(request.passion_projects)
        ) / 4.0
        
        # Calculate overall student strength
        student_strength = (academic_strength * 0.7) + (ec_strength * 0.3)
        
        # Get real college suggestions based on major
        major = request.major
        
        # Try to get balanced suggestions from real IPEDS data
        try:
            college_suggestions = real_college_suggestions.get_balanced_suggestions(major, student_strength)
            
            # If we don't have enough suggestions, use fallback
            if len(college_suggestions) < 9:
                college_suggestions = real_college_suggestions.get_fallback_suggestions(major, student_strength)
            
        except Exception as e:
            logger.error(f"Error getting real college suggestions: {e}")
            college_suggestions = real_college_suggestions.get_fallback_suggestions(major, student_strength)
        
        
        # Convert to API response format
        suggestions = []
        for college_data in college_suggestions[:9]:  # Ensure exactly 9 suggestions
            college_name = college_data['name']
            
            # Use the probability already calculated by the real_college_suggestions system
            probability = college_data.get('probability', 0.5)
            
            # Get major relevance info
            major_relevance = get_major_relevance_info(college_name, major)
            
            # Handle NaN values for enrollment
            student_body_size = college_data['student_body_size']
            if pd.isna(student_body_size) or student_body_size is None:
                enrollment_str = "N/A"
                student_body_size = 0
            else:
                enrollment_str = f"{int(student_body_size):,}"
            
            suggestion = {
                'college_id': f"college_{college_data['unitid']}",
                'name': college_name,
                'probability': safe_round(probability, 4),
                'original_probability': safe_round(probability, 4),
                'major_fit_score': safe_round(college_data['major_fit_score'], 2),
                'confidence_interval': {
                    "lower": safe_round(max(0.01, probability - 0.1), 4),
                    "upper": safe_round(min(0.95, probability + 0.1), 4)
                },
                'acceptance_rate': safe_float(college_data['acceptance_rate'], 0.5),
                'selectivity_tier': college_data['selectivity_tier'],
                'tier': college_data['selectivity_tier'],
                'city': college_data['city'],
                'state': college_data['state'],
                'tuition_in_state': safe_float(college_data['tuition_in_state'], 0),
                'tuition_out_of_state': safe_float(college_data['tuition_out_of_state'], 0),
                'student_body_size': safe_float(student_body_size, 0),
                'enrollment': enrollment_str,
                'category': college_data['category'],
                'major_match': major_relevance['match_level'],
                'major_relevance_score': safe_round(major_relevance['score'], 2)
            }
            
            suggestions.append(suggestion)
        
        # Calculate academic score for response (ensure JSON-compliant)
        academic_score = safe_float((gpa_unweighted * 25) + (sat_score * 0.1) + (act_score * 2.5) + (ec_strength * 5), 0)
        
        # Determine target tiers based on academic strength
        target_tiers = []
        if academic_strength >= 8.0:
            target_tiers = ['Elite', 'Highly Selective']
        elif academic_strength >= 6.0:
            target_tiers = ['Highly Selective', 'Moderately Selective']
        else:
            target_tiers = ['Moderately Selective', 'Less Selective']
        
        # Prepare response
        response_data = {
            "success": True,
            "suggestions": suggestions,
            "academic_score": round(academic_score, 2),
            "target_tiers": target_tiers,
            "prediction_method": "real_ipeds_data"
        }
        
        # Cache the response
        suggestion_cache[cache_key] = (response_data, current_time)
        
        logger.info(f"Cached suggestions for key: {cache_key[:20]}...")
        
        return response_data
        
    except Exception as e:
        logger.error(f"Error in suggest_colleges: {e}")
        import traceback
        logger.error(f"Traceback: {traceback.format_exc()}")
        return {"success": False, "error": str(e), "suggestions": [], "traceback": traceback.format_exc()}

@app.post("/predict")
async def predict_admission(request: PredictionRequest):
    """Predict admission probability using ML model"""
    try:
        # Get predictor
        predictor = get_predictor()
        
        # Create student features
        student = StudentFeatures(
            gpa_unweighted=request.gpa_unweighted,
            gpa_weighted=request.gpa_weighted,
            sat_score=request.sat,
            act_score=request.act,
            rigor_score=request.extracurricular_depth / 10.0,  # Convert to 0-1 scale
            factor_scores={
                'extracurricular_depth': request.extracurricular_depth / 10.0,
                'leadership_positions': request.leadership_positions / 10.0,
                'awards_publications': request.awards_publications / 10.0,
                'passion_projects': request.passion_projects / 10.0,
                'business_ventures': request.business_ventures / 10.0,
                'volunteer_work': request.volunteer_work / 10.0,
                'research_experience': request.research_experience / 10.0,
                'portfolio_audition': request.portfolio_audition / 10.0,
                'essay_quality': request.essay_quality / 10.0,
                'recommendations': request.recommendations / 10.0,
                'interview': request.interview / 10.0,
                'demonstrated_interest': request.demonstrated_interest / 10.0,
                'legacy_status': request.legacy_status / 10.0,
                'geographic_diversity': request.geographic_diversity / 10.0,
                'firstgen_diversity': request.firstgen_diversity / 10.0,
                'hs_reputation': request.hs_reputation / 10.0,
            }
        )
        
        # Create college features based on the selected college
        # Map college selection to actual training data
        college_data = get_college_data(request.college)
        college = CollegeFeatures(
            name=request.college,
            acceptance_rate=college_data['acceptance_rate'],
            sat_25th=college_data.get('sat_25th', 1200),
            sat_75th=college_data.get('sat_75th', 1500),
            act_25th=college_data.get('act_25th', 25),
            act_75th=college_data.get('act_75th', 35),
            test_policy=college_data.get('test_policy', 'Required'),
            financial_aid_policy=college_data.get('financial_aid_policy', 'Need-blind'),
            selectivity_tier=college_data.get('selectivity_tier', 'Elite')
        )
        
        # Make prediction
        result = predictor.predict(student, college)
        
        # Determine outcome based on probability
        if result.probability >= 0.7:
            outcome = "Acceptance"
        elif result.probability >= 0.3:
            outcome = "Waitlist"
        else:
            outcome = "Rejection"
        
        return {
            "probability": result.probability,
            "outcome": outcome,
            "confidence": result.ml_confidence,
            "model_used": result.model_used,
            "explanation": result.explanation
        }
        
    except Exception as e:
        logger.error(f"Prediction error: {e}")
        # Return mock result for development
        import random
        mock_prob = random.uniform(0.2, 0.8)
        if mock_prob >= 0.7:
            outcome = "Acceptance"
        elif mock_prob >= 0.3:
            outcome = "Waitlist"
        else:
            outcome = "Rejection"
            
        return {
            "probability": mock_prob,
            "outcome": outcome,
            "confidence": 0.85,
            "model_used": "mock",
            "explanation": "Mock prediction for development"
        }

# Debug endpoint to force reload predictor
@app.get("/api/debug/reload-predictor")
async def debug_reload_predictor():
    """Debug endpoint to force reload the ML predictor."""
    try:
        from ml.models.predictor import get_predictor
        predictor = get_predictor(force_reload=True)
        return {
            "status": "success",
            "message": "Predictor reloaded",
            "models_available": len(predictor.models),
            "scaler_available": predictor.scaler is not None,
            "feature_selector_available": predictor.feature_selector is not None,
            "available_models": list(predictor.models.keys())
        }
    except Exception as e:
        return {
            "status": "error",
            "message": f"Failed to reload predictor: {str(e)}"
        }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run("main:app", host="0.0.0.0", port=8000, reload=True)

 
 
